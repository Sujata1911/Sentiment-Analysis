{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_E6oV3lV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  word_count\n",
       "0   @user when a father is dysfunctional and is s...          21\n",
       "1  @user @user thanks for #lyft credit i can't us...          22\n",
       "2                                bihday your majesty           5\n",
       "3  #model   i love u take with u all the time in ...          17\n",
       "4             factsguide: society now    #motivation           8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. BASIC FEATURE EXTRACTION\n",
    "#(1.1)\n",
    "#extracting number of words in each tweet\n",
    "#negative sentiments generally have less number of words\n",
    "train['word_count'] = train['tweet'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train[['tweet','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  char_count\n",
       "0   @user when a father is dysfunctional and is s...         102\n",
       "1  @user @user thanks for #lyft credit i can't us...         122\n",
       "2                                bihday your majesty          21\n",
       "3  #model   i love u take with u all the time in ...          86\n",
       "4             factsguide: society now    #motivation          39"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1.2)\n",
    "#number of characters in each tweet\n",
    "#using length of the tweet\n",
    "train['char_count'] = train['tweet'].str.len() ## this also includes spaces\n",
    "train[['tweet','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>4.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>5.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>4.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  avg_word\n",
       "0   @user when a father is dysfunctional and is s...  4.555556\n",
       "1  @user @user thanks for #lyft credit i can't us...  5.315789\n",
       "2                                bihday your majesty  5.666667\n",
       "3  #model   i love u take with u all the time in ...  4.928571\n",
       "4             factsguide: society now    #motivation  8.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1.3)\n",
    "#average length of the tweet\n",
    "#sum of length of all the words/the total length of the tweet\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "train['avg_word'] = train['tweet'].apply(lambda x: avg_word(x))\n",
    "train[['tweet','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  stopwords\n",
       "0   @user when a father is dysfunctional and is s...         10\n",
       "1  @user @user thanks for #lyft credit i can't us...          5\n",
       "2                                bihday your majesty          1\n",
       "3  #model   i love u take with u all the time in ...          5\n",
       "4             factsguide: society now    #motivation          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1.4)\n",
    "#number of stopwords\n",
    "#sometimes calculating the number of stopwords can also give us some extra information which we might have been losing before\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['stopwords'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "train[['tweet','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  hastags\n",
       "0   @user when a father is dysfunctional and is s...        1\n",
       "1  @user @user thanks for #lyft credit i can't us...        3\n",
       "2                                bihday your majesty        0\n",
       "3  #model   i love u take with u all the time in ...        1\n",
       "4             factsguide: society now    #motivation        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1.5)\n",
    "#calculating the number of hashtags or mentions present in it\n",
    "#helps in extracting extra information from our text data\n",
    "#using ‘starts with’ function because hashtags (or mentions) always appear at the beginning of a word\n",
    "train['hastags'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "train[['tweet','hastags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  numerics\n",
       "0   @user when a father is dysfunctional and is s...         0\n",
       "1  @user @user thanks for #lyft credit i can't us...         0\n",
       "2                                bihday your majesty         0\n",
       "3  #model   i love u take with u all the time in ...         0\n",
       "4             factsguide: society now    #motivation         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1.6)\n",
    "#calculating number of numerics\n",
    "train['numerics'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "train[['tweet','numerics']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  upper\n",
       "0   @user when a father is dysfunctional and is s...      0\n",
       "1  @user @user thanks for #lyft credit i can't us...      0\n",
       "2                                bihday your majesty      0\n",
       "3  #model   i love u take with u all the time in ...      0\n",
       "4             factsguide: society now    #motivation      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1.7)\n",
    "#number of uppercase words\n",
    "#Anger or rage is often expressed by writing in UPPERCASE words \n",
    "#which makes this a necessary operation to identify those words\n",
    "train['upper'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "train[['tweet','upper']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @user when a father is dysfunctional and is so...\n",
       "1    @user @user thanks for #lyft credit i can't us...\n",
       "2                                  bihday your majesty\n",
       "3    #model i love u take with u all the time in ur...\n",
       "4                  factsguide: society now #motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. BASIC PRE-PROCESSING\n",
    "#(2.1) Lowercase - transforming data to lowercase\n",
    "#helps avoid having multiple copies of the same word(careful with Apple and apple)\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    user when a father is dysfunctional and is so ...\n",
       "1    user user thanks for lyft credit i cant use ca...\n",
       "2                                  bihday your majesty\n",
       "3    model i love u take with u all the time in urð...\n",
       "4                    factsguide society now motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2.2) Remove punctuations (since it doesnt add any extra information)\n",
    "train['tweet'] = train['tweet'].str.replace('[^\\w\\s]','')\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    user father dysfunctional selfish drags kids d...\n",
       "1    user user thanks lyft credit cant use cause do...\n",
       "2                                       bihday majesty\n",
       "3                model love u take u time urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2.3) remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(2.4) Common Word Removal\n",
    "#let’s check the 10 most frequently occurring words in our text data\n",
    "freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user     17473\n",
       "love      2647\n",
       "ð         2511\n",
       "day       2199\n",
       "â         1797\n",
       "happy     1663\n",
       "amp       1582\n",
       "im        1139\n",
       "u         1136\n",
       "time      1110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                              model take urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take call to remove\n",
    "freq = list(freq.index)\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(2.5) Rare word Removal\n",
    "#Because they’re so rare, the association between them and other words is dominated by noise\n",
    "freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onðð                    1\n",
       "spencer                 1\n",
       "maytheforcebewithyou    1\n",
       "learningâ               1\n",
       "pfyp                    1\n",
       "thehuntingpay           1\n",
       "getityourself           1\n",
       "robben                  1\n",
       "basquetball             1\n",
       "160                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kids dysfun...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                              model take urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take call to remove rare words\n",
    "freq = list(freq.index)\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kiss dysfun...\n",
       "1    thanks left credit can use cause dont offer wh...\n",
       "2                                       midday majesty\n",
       "3                               model take or ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2.6) Spelling Correction\n",
    "#to reduce multiple copies of words\n",
    "#eg. “Analytics” and “analytcs” will be treated as different words even if they are used in the same sense\n",
    "#achieved using textblob library\n",
    "from textblob import TextBlob\n",
    "train['tweet'][:5].apply(lambda x: str(TextBlob(x).correct()))\n",
    "#it is time-consuming\n",
    "#Therefore, just for the purposes of learning, applying it on only the first 5 rows\n",
    "#Not always accurate\n",
    "#Words are often used in their abbreviated form\n",
    "#eg.‘your’ is used as ‘ur’ but using this tramsforms it to 'or' instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['thanks', 'lyft', 'credit', 'cant', 'use', 'cause', 'dont', 'offer', 'wheelchair', 'vans', 'pdx', 'disapointed', 'getthanked'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2.7) tokenization\n",
    "#Conversion into words or sentences\n",
    "#textblob library to first transform our tweets into a blob and then converted them into a series of words\n",
    "TextBlob(train['tweet'][1]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        father dysfunct selfish drag kid dysfunct run\n",
       "1    thank lyft credit cant use caus dont offer whe...\n",
       "2                                       bihday majesti\n",
       "3                              model take urð ðððð ððð\n",
       "4                              factsguid societi motiv\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2.8) Stemming\n",
    "#Conversion into root words\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "train['tweet'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drag kid dysfunct...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                              model take urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2.9) Lemmatization\n",
    "# converts the word into its root word, rather than just stripping the suffices\n",
    "# makes use of the vocabulary and does a morphological analysis to obtain the root word\n",
    "from textblob import Word\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['father', 'dysfunctional']),\n",
       " WordList(['dysfunctional', 'selfish']),\n",
       " WordList(['selfish', 'drag']),\n",
       " WordList(['drag', 'kid']),\n",
       " WordList(['kid', 'dysfunction']),\n",
       " WordList(['dysfunction', 'run'])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 ADVANCED TEXT PROCESSING - extracting features\n",
    "#(3.1) N-Grams\n",
    "#Extracting bigrams\n",
    "TextBlob(train['tweet'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(3.2) Term Frequency\n",
    "#TF = (Number of times term T appears in the particular row) / (number of terms in that row)\n",
    "tf1 = (train['tweet'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dont</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>use</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lyft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>offer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>disapointed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>getthanked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  tf\n",
       "0        thanks   1\n",
       "1           pdx   1\n",
       "2        credit   1\n",
       "3    wheelchair   1\n",
       "4          cant   1\n",
       "5          dont   1\n",
       "6           use   1\n",
       "7           van   1\n",
       "8          lyft   1\n",
       "9         cause   1\n",
       "10        offer   1\n",
       "11  disapointed   1\n",
       "12   getthanked   1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3.3) IDF Inverse Document Frequency\n",
    "#A word is not of much use to us if it’s appearing in all the documents\n",
    "#Therefore, IDF of each word is log of (total number of rows)/(number of rows in which that word is present)\n",
    "#IDF = log(N/n), \n",
    "#where, N is the total number of rows, n is the number of rows in which the word was present\n",
    "import numpy as np\n",
    "for i,word in enumerate(tf1['words']):\n",
    "    tf1.loc[i, 'idf'] = np.log(train.shape[0]/(len(train[train['tweet'].str.contains(word)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1</td>\n",
       "      <td>4.597751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdx</td>\n",
       "      <td>1</td>\n",
       "      <td>8.762865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit</td>\n",
       "      <td>1</td>\n",
       "      <td>7.327781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>1</td>\n",
       "      <td>9.273691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cant</td>\n",
       "      <td>1</td>\n",
       "      <td>3.538194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dont</td>\n",
       "      <td>1</td>\n",
       "      <td>3.745585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>use</td>\n",
       "      <td>1</td>\n",
       "      <td>3.552287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "      <td>5.236505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lyft</td>\n",
       "      <td>1</td>\n",
       "      <td>8.762865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>5.690172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>offer</td>\n",
       "      <td>1</td>\n",
       "      <td>6.522155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>disapointed</td>\n",
       "      <td>1</td>\n",
       "      <td>10.372303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>getthanked</td>\n",
       "      <td>1</td>\n",
       "      <td>9.679156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  tf        idf\n",
       "0        thanks   1   4.597751\n",
       "1           pdx   1   8.762865\n",
       "2        credit   1   7.327781\n",
       "3    wheelchair   1   9.273691\n",
       "4          cant   1   3.538194\n",
       "5          dont   1   3.745585\n",
       "6           use   1   3.552287\n",
       "7           van   1   5.236505\n",
       "8          lyft   1   8.762865\n",
       "9         cause   1   5.690172\n",
       "10        offer   1   6.522155\n",
       "11  disapointed   1  10.372303\n",
       "12   getthanked   1   9.679156"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1\n",
    "#higher value of idf indicates how unique the word is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(3.4)Term Frequency – Inverse Document Frequency = (TF)*(IDF)\n",
    "#penalises commonly occuring words\n",
    "#gives high weight to words like 'disappointed' because they help in determining the sentiment of the tweet\n",
    "#instead of using this: \n",
    "#tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "#tf1, sklearn package can directly be used\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31962x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 114036 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vect\n",
    "#pre-processing steps like lower-casing and removal of stopwords can also be performed before this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(3.5)Bag of Words\n",
    "#refers to representation of text which describes the presence of words within the text data\n",
    "#two similar text fields will contain similar kind of words, and will therefore have a similar bag of word\n",
    "#from the text alone we can learn something about the meaning of the document\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31962x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 128386 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (-0.3, 0.5354166666666667)\n",
       "1                    (0.2, 0.2)\n",
       "2                    (0.0, 0.0)\n",
       "3                    (0.0, 0.0)\n",
       "4                    (0.0, 0.0)\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(3.6.i) Checking the sentiment of first few tweets\n",
    "train['tweet'][:5].apply(lambda x: TextBlob(x).sentiment)\n",
    "#Here, we only extract polarity\n",
    "#indicated: value nearer to 1 = positive sentiment and values nearer to -1 = negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks lyft credit cant use cause dont offer w...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model take urð ðððð ððð</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  father dysfunctional selfish drag kid dysfunct...       -0.3\n",
       "1  thanks lyft credit cant use cause dont offer w...        0.2\n",
       "2                                     bihday majesty        0.0\n",
       "3                            model take urð ðððð ððð        0.0\n",
       "4                      factsguide society motivation        0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using above idea as a feature for building a machine learning model\n",
    "train['sentiment'] = train['tweet'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "train[['tweet','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2196017, 300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(3.7) Word Embeddings\n",
    "#representation of text in the form of vectors\n",
    "#similar words will have a minimum distance between their vectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.840B.300d.txt'\n",
    "word2vec_output_file = 'glove.840B.300d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading the above file as a model\n",
    "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
    "filename = 'glove.840B.300d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.38929993e-01,  -1.90559998e-02,  -3.38910013e-01,\n",
       "         1.21509999e-01,   3.65229994e-01,  -1.73910007e-01,\n",
       "        -2.67350003e-02,  -5.03350012e-02,   2.47429997e-01,\n",
       "         2.45309997e+00,  -4.21130002e-01,   2.36320004e-01,\n",
       "         2.05129996e-01,  -1.09369997e-02,  -1.14799999e-01,\n",
       "        -3.76479998e-02,  -1.34399995e-01,   8.61240029e-01,\n",
       "        -3.58029991e-01,   9.25249979e-02,   2.80750006e-01,\n",
       "         1.36490002e-01,   2.08189994e-01,   6.02059998e-02,\n",
       "        -1.82290003e-01,   1.01719998e-01,  -1.31999999e-01,\n",
       "        -3.15979987e-01,   2.22409993e-01,  -1.90760002e-01,\n",
       "        -1.08840000e-02,   1.69880003e-01,   8.03450029e-03,\n",
       "         1.33369997e-01,   1.77239999e-01,  -1.91620007e-01,\n",
       "         3.36809993e-01,   3.01860005e-01,   6.16540015e-02,\n",
       "         7.69060012e-03,  -5.44059992e-01,   5.01420014e-02,\n",
       "        -4.31150012e-02,  -2.62410015e-01,   4.74620014e-02,\n",
       "         3.36699992e-01,  -2.86489993e-01,  -2.74140000e-01,\n",
       "         2.67760009e-02,  -6.59390017e-02,   1.10210001e-01,\n",
       "         2.88690001e-01,   4.67119992e-01,   1.20630004e-01,\n",
       "         3.38310003e-01,  -3.04270012e-04,  -1.21160001e-01,\n",
       "        -1.58999994e-01,  -1.05140001e-01,  -3.85599993e-02,\n",
       "        -6.22050017e-02,   3.56310010e-02,  -1.78519994e-01,\n",
       "        -1.33080006e-01,   2.61029989e-01,  -1.10820003e-01,\n",
       "        -2.74630010e-01,   1.85560003e-01,   4.52569991e-01,\n",
       "         3.03359985e-01,   6.18010014e-02,   7.73100033e-02,\n",
       "         3.46450001e-01,   3.65260011e-03,   4.68149990e-01,\n",
       "         2.02280004e-02,  -2.55089998e-02,  -1.94649994e-02,\n",
       "        -5.39979991e-03,   8.64970013e-02,  -5.30989990e-02,\n",
       "        -8.64259973e-02,  -4.69130009e-01,   6.57880008e-02,\n",
       "        -1.27200007e-01,  -2.42540002e-01,   2.41490006e-01,\n",
       "        -3.76839995e-01,   6.57069981e-01,   1.41059995e-01,\n",
       "        -2.10800007e-01,   1.10950001e-01,   1.27409995e-01,\n",
       "        -2.89380014e-01,  -7.52950013e-02,   4.41090018e-02,\n",
       "         5.42800017e-02,  -2.96660006e-01,   1.64230000e-02,\n",
       "         4.40860018e-02,   7.28619993e-02,  -3.01490009e-01,\n",
       "         3.46129984e-02,   8.67310017e-02,   3.10909986e-01,\n",
       "        -3.71560007e-01,   1.73820004e-01,   2.19960004e-01,\n",
       "         6.03119992e-02,   1.67669997e-01,   3.84690017e-02,\n",
       "        -6.32309973e-01,   3.23309988e-01,   1.04209997e-01,\n",
       "         2.50800014e-01,   2.62670010e-01,   1.78819999e-01,\n",
       "        -2.45150000e-01,  -1.72140002e-01,   2.83190012e-01,\n",
       "         6.55980036e-02,  -4.43859994e-02,   3.70640010e-02,\n",
       "         4.50179987e-02,   3.93669993e-01,  -1.35800004e-01,\n",
       "        -4.60209996e-02,   2.32600003e-01,   3.41559984e-02,\n",
       "         8.48380029e-02,   3.80560011e-02,  -3.46589996e-03,\n",
       "        -6.81769997e-02,   8.26060027e-02,   1.58109993e-01,\n",
       "        -1.93880007e-01,   6.12469986e-02,  -3.42819989e-01,\n",
       "        -2.33919993e-01,   9.11310017e-02,  -2.09340000e+00,\n",
       "         1.38150007e-01,   1.75970003e-01,  -3.80050004e-01,\n",
       "         2.46900007e-01,  -2.24820003e-01,  -5.94150014e-02,\n",
       "         4.24149990e-01,  -1.37679994e-01,  -6.41840026e-02,\n",
       "        -6.32300004e-02,   1.02279998e-01,   3.96619998e-02,\n",
       "        -2.89099991e-01,   8.02420005e-02,  -4.28539991e-01,\n",
       "         1.04740001e-01,  -1.40699998e-01,  -5.04200011e-02,\n",
       "        -1.34859994e-01,  -1.30769998e-01,  -1.15599997e-01,\n",
       "        -3.76480013e-01,   1.44670000e-02,   2.84000002e-02,\n",
       "        -1.49210006e-01,   2.90289998e-01,  -9.91630033e-02,\n",
       "         2.29670003e-01,   4.97170016e-02,  -2.43450001e-01,\n",
       "         2.77219992e-02,   7.40550011e-02,  -4.25790012e-01,\n",
       "         1.67239994e-01,   6.54689968e-02,   7.75709972e-02,\n",
       "         2.15289995e-01,  -7.13300034e-02,  -5.27420007e-02,\n",
       "         1.20800003e-01,  -5.65030016e-02,  -3.58520001e-01,\n",
       "        -8.56409967e-02,   5.33640027e-01,   1.81889996e-01,\n",
       "        -1.78870007e-01,  -2.01000005e-01,   4.36549991e-01,\n",
       "         1.79120004e-01,   2.22379994e-02,  -4.84910011e-02,\n",
       "        -8.83470029e-02,  -1.75439999e-01,  -1.70519993e-01,\n",
       "         2.75779992e-01,  -2.76289999e-01,  -5.60300015e-02,\n",
       "         3.04159999e-01,   4.51150000e-01,   6.84399977e-02,\n",
       "        -1.59260005e-01,  -2.71970004e-01,  -2.26280000e-02,\n",
       "         3.45670015e-01,  -8.86219963e-02,   1.93580002e-01,\n",
       "        -4.16529998e-02,   4.16610003e-01,   1.08479999e-01,\n",
       "        -6.97520003e-02,  -2.37489998e-01,  -1.85110003e-01,\n",
       "         8.85349978e-03,  -1.27729997e-01,  -8.28019977e-02,\n",
       "         4.57939990e-02,   3.35539997e-01,  -3.06439996e-01,\n",
       "         4.41709995e-01,   1.59750000e-01,  -1.27560003e-02,\n",
       "        -2.69719988e-01,  -7.89770037e-02,  -4.82640006e-02,\n",
       "        -6.59620017e-02,  -3.00060004e-01,   1.04400001e-01,\n",
       "        -1.27149999e-01,  -1.44880004e-02,  -3.51069987e-01,\n",
       "        -1.14069998e-01,   6.63429976e-01,   1.65889993e-01,\n",
       "         1.50400000e-02,  -8.32489971e-03,   1.38349999e-02,\n",
       "        -1.95999995e-01,  -3.61299999e-02,   2.03370005e-01,\n",
       "         1.18220001e-01,   1.47599995e-01,  -3.90740000e-02,\n",
       "         2.46189997e-01,  -9.62800011e-02,  -2.27190003e-01,\n",
       "        -2.25970000e-01,   1.92359999e-01,  -4.13619995e-01,\n",
       "         3.78210008e-01,   2.81140000e-01,  -7.82319978e-02,\n",
       "        -2.48520002e-01,   8.49779993e-02,   4.56800014e-01,\n",
       "         4.78179991e-01,  -7.21919984e-02,  -2.24409997e-01,\n",
       "        -2.57129997e-01,   1.18199997e-01,   1.80280000e-01,\n",
       "         5.11810005e-01,   4.09040004e-01,  -2.43039995e-01,\n",
       "         4.90900010e-01,  -3.97069991e-01,  -5.19630015e-02,\n",
       "         1.78180002e-02,   2.51599997e-01,   2.82900006e-01,\n",
       "         2.27760002e-01,  -2.58439988e-01,   1.42810002e-01,\n",
       "        -7.26070032e-02,   1.51940003e-01,   2.53089994e-01,\n",
       "         4.72319983e-02,   2.59050012e-01,  -9.33130011e-02,\n",
       "         1.12259999e-01,  -1.74490005e-01,  -3.48960012e-01,\n",
       "        -2.01450005e-01,   1.16279997e-01,  -1.07689999e-01,\n",
       "        -7.85280019e-02,   9.30960029e-02,  -1.65390000e-01,\n",
       "         4.39939983e-02,   5.96980006e-02,  -1.30469993e-01,\n",
       "         7.21469969e-02,   3.36629990e-03,  -1.81810006e-01,\n",
       "         3.14650014e-02,  -3.53510007e-02,  -4.79120016e-03,\n",
       "         9.27530006e-02,   2.86179990e-01,   1.36460006e-01], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.53040010e-01,   1.03629999e-01,  -2.32190005e-02,\n",
       "         1.69939995e-01,   2.22729996e-01,  -2.68660009e-01,\n",
       "        -4.60290015e-01,  -1.61709994e-01,  -2.63289995e-02,\n",
       "         2.92149997e+00,   4.22010012e-02,   3.83540004e-01,\n",
       "        -9.18510035e-02,  -2.02150002e-01,  -1.59960002e-01,\n",
       "        -2.67069995e-01,  -2.30960008e-02,   7.17239976e-01,\n",
       "        -1.53679997e-01,   1.96669996e-01,   9.34500024e-02,\n",
       "         2.24309996e-01,  -4.59459983e-02,   2.05160007e-01,\n",
       "         4.52539995e-02,  -6.43279999e-02,  -6.82540014e-02,\n",
       "        -2.39140004e-01,  -9.19890031e-02,  -3.15789990e-02,\n",
       "        -4.46229987e-02,   2.67910004e-01,  -7.01160014e-01,\n",
       "        -1.12760000e-01,   2.36560002e-01,  -6.27140030e-02,\n",
       "        -8.37529972e-02,   2.97930002e-01,   7.55629987e-02,\n",
       "         1.89549997e-01,   9.14330035e-03,  -1.26230001e-01,\n",
       "        -2.27799997e-01,  -6.04370013e-02,   1.51380002e-01,\n",
       "         5.64199984e-02,  -3.10369998e-01,  -2.93850005e-01,\n",
       "        -5.61200023e-01,   1.13899998e-01,   6.83450028e-02,\n",
       "         1.46280006e-01,  -1.48069993e-01,   5.79009987e-02,\n",
       "         3.90349999e-02,   9.54219997e-02,   2.78689992e-02,\n",
       "         1.09090000e-01,   7.58550018e-02,  -5.40350005e-02,\n",
       "         1.49880007e-01,  -4.92869988e-02,  -1.46709997e-02,\n",
       "        -1.24250002e-01,   1.52209997e-01,  -4.80119996e-02,\n",
       "        -4.07820009e-02,   1.72110006e-01,   5.25059998e-01,\n",
       "         1.99790001e-01,   1.05949998e-01,   2.48649999e-01,\n",
       "         3.28209996e-01,   7.29990005e-02,  -1.47320002e-01,\n",
       "        -6.59909993e-02,   4.48689997e-01,  -7.26400018e-02,\n",
       "         2.57829994e-01,  -6.03279984e-03,   1.87619999e-01,\n",
       "         1.51099995e-01,  -1.05209999e-01,  -5.24209976e-01,\n",
       "        -2.18559995e-01,  -8.29429999e-02,   2.06819996e-01,\n",
       "        -1.66510001e-01,   4.31600004e-01,   3.36510018e-02,\n",
       "        -8.46389979e-02,   9.97549966e-02,  -1.73790008e-02,\n",
       "        -2.41500005e-01,   1.30400002e-01,   1.53540000e-01,\n",
       "        -1.36110000e-02,  -1.48460001e-01,  -3.33880007e-01,\n",
       "        -1.51690006e-01,   3.72040004e-01,  -2.09260010e-03,\n",
       "        -4.14970011e-01,   4.34780009e-02,   7.23629966e-02,\n",
       "        -6.37390018e-01,   4.17959988e-01,   4.47439998e-01,\n",
       "        -2.63880007e-02,   4.53610010e-02,   2.30460003e-01,\n",
       "        -3.11379999e-01,   6.23020008e-02,   2.26380005e-02,\n",
       "         3.17450017e-02,  -6.02429993e-02,  -1.69620007e-01,\n",
       "         1.96429998e-01,  -9.02459994e-02,   3.26570004e-01,\n",
       "         1.57680005e-01,  -3.19380015e-02,   2.45419994e-01,\n",
       "        -1.81009993e-01,  -8.85109976e-02,  -5.90430014e-02,\n",
       "        -1.68329999e-01,   2.10679993e-01,   1.36700004e-01,\n",
       "        -2.49730004e-03,  -2.13919997e-01,  -1.45600006e-01,\n",
       "         1.24420002e-02,  -1.34090006e-01,   1.14100002e-01,\n",
       "        -1.21080004e-01,  -1.19970001e-01,   3.21339995e-01,\n",
       "         5.51539995e-02,   1.11720003e-01,  -1.80400002e+00,\n",
       "         6.65840030e-01,   2.04349995e-01,  -2.01040000e-01,\n",
       "         2.92070001e-01,   1.92629993e-01,  -3.04360002e-01,\n",
       "         3.06650013e-01,   2.90470004e-01,   2.35139996e-01,\n",
       "         2.47940004e-01,  -1.53589994e-01,   2.18219995e-01,\n",
       "        -3.35970014e-01,  -2.39720002e-01,  -1.57979995e-01,\n",
       "         1.18170001e-01,   2.29179993e-01,  -2.73759998e-02,\n",
       "        -1.55650005e-01,  -9.90649965e-03,  -2.67140001e-01,\n",
       "         8.36540014e-02,   1.72749996e-01,   3.46049994e-01,\n",
       "         4.53649983e-02,  -8.78039971e-02,  -3.18549983e-02,\n",
       "         1.55279994e-01,   8.54289979e-02,   6.81580007e-02,\n",
       "        -2.93550014e-01,  -3.24600011e-01,  -4.90029991e-01,\n",
       "        -1.67480007e-01,   1.70959998e-02,  -1.06640002e-02,\n",
       "        -1.12700000e-01,  -1.78180002e-02,  -1.43660000e-02,\n",
       "         1.46380007e-01,  -5.23949981e-01,   2.97390014e-01,\n",
       "        -2.11270005e-01,   3.82290006e-01,  -5.60990013e-02,\n",
       "        -2.80479997e-01,  -1.22249998e-01,   4.88359988e-01,\n",
       "         2.47419998e-01,   2.35750005e-01,  -2.05359995e-01,\n",
       "        -5.97640015e-02,  -8.97480026e-02,   1.04839997e-02,\n",
       "         4.69980016e-02,  -2.75799990e-01,  -3.23509991e-01,\n",
       "        -1.80710003e-01,   3.77429992e-01,  -9.58999991e-02,\n",
       "        -1.81569993e-01,  -1.28270000e-01,   1.62700005e-03,\n",
       "         2.12730005e-01,   7.01900005e-01,   2.25439996e-01,\n",
       "        -3.72099996e-01,  -5.00020012e-02,  -5.51829994e-01,\n",
       "         2.88490001e-02,  -6.16729975e-01,   3.92239988e-02,\n",
       "        -1.53940003e-02,   2.17710003e-01,  -1.68909997e-01,\n",
       "         3.58130008e-01,   1.19670004e-01,  -2.21729994e-01,\n",
       "         1.59669995e-01,  -1.25599995e-01,  -1.18790001e-01,\n",
       "        -2.83289999e-01,  -1.38600007e-01,  -4.14490014e-01,\n",
       "        -4.85570014e-01,  -7.80870020e-02,   2.91610003e-01,\n",
       "        -2.19459996e-01,  -2.26119999e-02,   2.51329988e-01,\n",
       "         1.32540002e-01,   5.11449993e-01,  -9.34090000e-03,\n",
       "         8.94730017e-02,  -2.72259992e-02,   3.69630009e-01,\n",
       "        -3.54529992e-02,  -3.42810005e-01,   2.03910004e-02,\n",
       "         2.39150003e-01,   6.66270033e-02,  -1.12800002e-01,\n",
       "         4.85089988e-01,  -1.48330003e-01,  -1.99579999e-01,\n",
       "        -4.63539988e-01,  -4.65399995e-02,  -3.03860009e-01,\n",
       "         3.56110007e-01,  -2.69309998e-01,  -2.60989994e-01,\n",
       "         1.63680002e-01,   7.38710016e-02,   1.54170007e-01,\n",
       "         6.35730028e-01,  -2.00320005e-01,  -3.72090012e-01,\n",
       "         2.95969993e-02,   2.89310008e-01,  -2.65009999e-01,\n",
       "         3.01589996e-01,   4.38589990e-01,  -1.82870001e-01,\n",
       "         6.02010012e-01,   7.08969980e-02,  -2.52620012e-01,\n",
       "        -2.92219996e-01,  -5.41630030e-01,  -2.97069997e-01,\n",
       "         5.68990000e-02,  -2.98079997e-01,  -4.02589999e-02,\n",
       "        -6.35770023e-01,   2.04260007e-01,   9.67099965e-02,\n",
       "         3.30350012e-01,   2.17329994e-01,  -4.53799993e-01,\n",
       "         9.49640016e-05,  -1.71729997e-01,  -8.68630037e-02,\n",
       "        -1.18699998e-01,  -1.60540000e-01,  -7.88519979e-02,\n",
       "        -1.68880001e-01,   5.22530004e-02,  -3.05469990e-01,\n",
       "         2.10859999e-03,  -1.69850007e-01,  -2.30959997e-01,\n",
       "         6.92310035e-02,  -1.09900003e-02,   8.55799988e-02,\n",
       "         2.35200003e-01,   6.46380037e-02,  -3.36949993e-03,\n",
       "         3.15200001e-01,  -1.10349998e-01,  -5.21680005e-02], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
